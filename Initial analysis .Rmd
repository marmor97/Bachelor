---
title: "Initial analysis"
author: "Marie Mortensen"
date: "10/19/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

PACKAGES AND FUNCTIONS
```{r}
pacman::p_load(tidyverse, readr, glmnet, data.table, broom, forcats, e1071, cvms)
source("functions/Inspection.R")
source("functions/Normalize_function.R")
source("cv funtions .R")
```

READING FILES AND MERGING WITH DEMODATA
```{r}
gemap_us_dk <- read_csv("gemap_all_us_dk_v2.csv")

#reading demodata
demo <- read_csv("../DemoData.csv")
# colnames(gemap_us_dk)[2] <- "ID_original" #as some IDs in feature files contain letters and they don't in demodata they are 
#saved in another column
# gemap_us_dk <- gemap_us_dk %>% mutate(
#   ID = as.character(str_extract(ID_original, "[0-9]*")) #in order to merge with demodata we extract only numbers from the original ID column) 
# colnames(gemap_us_dk)[2] <- "ID"

u_gemap <- unique(gemap_us_dk$ID) #unique IDs
u_demo <- unique(demo$ID)

missing_id <- setdiff(u_demo,u_gemap)#seeing which IDs are not represented in u_gemap
#MEN NOGLE AF DEM ER DER! DET HAR STINE TJEKKET. DEM MED 100 HAR IKKE MED ALLE ANDRE HAR?!?!?!?!??!?!

gemap_us_dk <- gemap_us_dk %>% 
  mutate(
  ID_letter = str_extract(name, "[A-Z]*"),
  ID_number = str_extract(name, "[0-9]*")
) 
gemap_us_dk$ID
gemap_us_dk <- gemap_us_dk %>% 
  unite(ID, ID_letter:ID_number, sep = "")

```

NORMALIZING AND PARTITIONING
```{r}
#partitioning
partitions <- partition_func(features = gemap_us_dk, demo = demo, n= 109) #partition_func returns a list with two elements; first element is hold_out and second is train
train <- partitions[[2]]
hold_out <- partitions[[1]]

unique(train$ID)
unique(hold_out$ID)

#normalizing
train_scaled <- as.data.frame(
  scale_function(train, #scale_function takes min and max of all columns in train and subtracts min from all values in each columns and divides by max value to get the empirically scaled columns
                 datatype = "train"))

hold_out_scaled <- as.data.frame(
  scale_function(train, 
                 hold_out, 
                 datatype = "test"))
```


COMBINING DEMO AND FEATURES 
```{r}
gemap <- gemap_us_dk  %>% #combining demodata and features
  left_join(demo, 
            by = "ID") %>% 
  mutate(
    Diagnosis = as.factor(Diagnosis) #changing diagnosis column to factor
  )  %>% 
  select( #we will not use any of the descriptive columns in the analysis and remove them from the dataset 
    -c(X1,
       condition, 
       AdosSocial, 
       AdosStereotyped,
       PIQ,
       CARS,
       AdosCommunication,
       AdosCreativity,
       story_type,
       trial,
       ParentalEducation)
  )
```


REMOVING COLUMNS WITH WITH ZERO VARIATION
```{r}
badcolumns <- NULL #making an empty list
for (columns in 1:length(train_scaled)){ #every column in train
  if (is.factor(train_scaled[,columns])){ #is the column a factor?
    print(columns)
    if(uniqueN(train_scaled[,columns])<2){ #does the column have below 2 levels?
      bad_column_name <- colnames(train_scaled)[columns] #add the column name to a list of bad columns
      badcolumns <- c(badcolumns, bad_column_name) #combine it with the existing list
    }
  }
  if (is.numeric(train_scaled[,columns])){ #is the column numeric?
    print(columns)
    if(var(train_scaled[,columns], na.rm = T)==0|is.na(var(train_scaled[,columns]))){ #is variance 0?
      bad_column_name <- colnames(train_scaled)[columns]  #add the column name to a list of bad columns
      badcolumns <- c(badcolumns, bad_column_name)#combine it with the existing list
    }  
  }
}

train_scaled_clean <- train_scaled[ ,!(colnames(train_scaled) %in% c(badcolumns))] #keep only colnames that are NOT in the badcolumns list
colnames(train_scaled_clean) #columnames after 

#Maybe as well with hold_out

```

LASSO LAMDATUNING
```{r}
preds <- train_scaled_clean  %>% #combining demodata and features
  left_join(demo, 
            by = "ID")%>% 
  select( #specifying the columns that should not be included as predictors
  -c(X1,
    condition,
    name,
    ID, 
    frameTime, 
    language, 
    country, 
    feature_set, 
    story_type,
    Age,
    AdosCreativity,
    AdosSocial,
    AdosStereotyped,
    AdosCommunication,
    TIQ,
    PIQ,
    VIQ,
    SRS,
    PPVT,
    ParentalEducation,
    CARS,
    Leiter
     ) #selecting features that will not be predictors/features and saving as a new dataframe
)
colnames(preds)


x <- model.matrix(Diagnosis ~ ., data = preds) #making a matrix from formula
y <- preds$Diagnosis #choosing the dependent variable

lambdas_to_try <- 10^seq(-10, 10, length.out = 1000) #selecting lambdas

lasso_cv <- cv.glmnet(x, 
                      y, 
                      alpha = 1, # Setting alpha = 1 implements lasso regression
                      lambda = lambdas_to_try,
                      standardize = F, 
                      nfolds = 6, #6 folds means LOOCV
                      family = "binomial")



plot(lasso_cv)
#Accessing the best lambda and the coefficients 
#the best cross-validated lambda 
lasso_cv$lambda.min #log = -14.18765
lasso_cv$lambda.1se #log = -12.32697
```

LASSO COEFFICIENTS
```{r}
tidy(lasso_cv$glmnet.fit) %>%
  filter(lambda == lasso_cv$lambda.1se,
         term != "(Intercept)") %>% #selecting coefficients that are not the intercept
  mutate(term = fct_reorder(term, estimate)) %>% #this should reorder it to descending but not sure whether it does it
  ggplot(aes(term, estimate, fill = estimate > 0)) + #applying different colors to estimates above and below 0 
  geom_col() +
  theme_minimal() +
  coord_flip() +
  labs(y = "Estimated effect") +
  theme(legend.position = "none")

###measuring frequency of coefficients 
lasso_coef <- tidy(lasso_cv$glmnet.fit) %>%  
  filter(lambda == lasso_cv$lambda.1se,
         term != "(Intercept)") %>% 
  select(term, estimate) %>%  #maybe it arranges with absolute values already
  mutate(abs = abs(estimate),
         term = str_remove_all(term, "`")) %>% 
  filter(abs > 0)

lasso_desc <- lasso_coef %>% arrange(desc(abs)) #but now we have this and we need to find a universal way to save and count the occurences 

train_scaled_clean <- train_scaled_clean  %>% #combining demodata and features
  left_join(demo, 
            by = "ID")%>% 
  select( #specifying the columns that should not be included as predictors
  -c(X1,
    condition,
    name,
    # ID, 
    frameTime, 
    language, 
    country, 
    feature_set, 
    story_type,
    Age,
    AdosCreativity,
    AdosSocial,
    AdosStereotyped,
    AdosCommunication,
    TIQ,
    PIQ,
    VIQ,
    SRS,
    PPVT,
    ParentalEducation,
    CARS,
    Leiter
     ) #selecting features that will not be predictors/features and saving as a new dataframe
)
#selecting coefficients
train_lasso_features <- train_scaled_clean[,(colnames(train_scaled_clean) %in% lasso_coef$term)] #this makes a new dataframe where there are only the coefficients selected in our lasso feature reduction ##GENDER KOMMER IKKE MED
train_lasso_features$Gender <- train_scaled_clean$Gender

train_lasso_features <- train_lasso_features %>% 
  cbind(Diagnosis = train_scaled_clean$Diagnosis, #assuming that the order hasn't been changed we add the diagnosis and id from train_scaled clean
        ID = train_scaled_clean$ID) 


write.csv(train_lasso_features, "selcted_features_gemap.csv")
```

SVM
```{r}
mmatrix_lasso <- model.matrix(Diagnosis ~ ., train_lasso_features) #making a new matrix with reduced features 

#creating LOOCV folds
fold_train <- groupdata2::fold(train_lasso_features,
                               k = 66,
                               id_col = "ID"
)
fold_train[["Diagnosis"]] <- factor(fold_train[["Diagnosis"]])#making it a factor if it isn't already

# Cross-validate the model function
#sepcifying the hyperparams 
hyperparameters <- list( "cost" = c(0.001),
                         "kernel" = c("linear"))

hyperparameters <- list( "cost" = c(0.001,0.005,0.01,0.05),
                         "kernel" = c("linear"))
# The optional ".n" samples 4 combinations
svm_hparams <- list(
  ".n" = 12,
  "kernel" = c("linear", "radial", "sigmoid"),
  "cost" = c(0.001,0.005,0.01,0.05) #artikel "Typicality and Emotion in the Voice of Children with Autism Spectrum" bruger 0.001; 0.005; 0.01; 0,05
)

cv_linear <- cross_validate_fn(
  fold_train,
  formulas = "Diagnosis ~ .",
  type = "binomial",
  model_fn = svm_model_fn,
  predict_fn = svm_predict_fn,
  hyperparameters = hyperparameters,
  fold_cols = ".folds"
)

# The `HParams` column has the nested hyperparameter values
cv %>%
  select(Dependent, Fixed, HParams, `Balanced Accuracy`, F1, AUC, MCC) %>%
  tidyr::unnest(cols = "HParams") %>%
  arrange(desc(`Balanced Accuracy`), desc(F1))
```

PERFORMANCE
```{r}

```

